{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTurk Response Analysis\n",
    "\n",
    "Analysis of the inter-annotator agreement from the MTurk survey in which human and GPT morals were selected as either most or least applicable.\n",
    "\n",
    "Reproduces Tables 4 and 10 in our paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "from scipy.stats import chisquare\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa, aggregate_raters\n",
    "\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../data/validation/mturk'\n",
    "filename = 'mturk_responses.csv'\n",
    "\n",
    "df = pd.read_csv(os.path.join(filepath, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect the MTurker responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column names in the MTurk response file that contain the answers from the workers\n",
    "answer_cols = [\n",
    "    'central_topic__best',\n",
    "    'central_topic__worst', \n",
    "    'comprehension', \n",
    "    'moral__best', \n",
    "    'moral__worst',\n",
    "    'moral_neg__best', \n",
    "    'moral_neg__worst', \n",
    "    'moral_pos__best',\n",
    "    'moral_pos__worst'\n",
    "]\n",
    "\n",
    "# get the sub-dataframe containing the answers\n",
    "mturker_responses = df.sort_values(by=['story_type', 'file_index'])[['story_type', 'file_index', 'story_subtype'] + answer_cols]\n",
    "\n",
    "# get which answer (i.e. GPT, human1, human2) was selected\n",
    "mturker_responses.loc[:, answer_cols] = mturker_responses.loc[:, answer_cols].map(lambda s: s.split(\"_\")[0])\n",
    "\n",
    "# get when GPT was selected\n",
    "gpt_selection = mturker_responses.copy()\n",
    "gpt_selection.loc[:, answer_cols] = gpt_selection.loc[:, answer_cols].map(lambda s: s == 'GPT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the answers\n",
    "ans = df.sort_values(by=['story_type', 'file_index'])[['story_type', 'file_index', 'story_subtype'] + answer_cols]\n",
    "\n",
    "# which answer was selected\n",
    "ans.loc[:, answer_cols] = ans.loc[:, answer_cols].map(lambda s: s.split(\"_\")[0])\n",
    "\n",
    "# get when GPT was selected\n",
    "gpt_selection = ans.copy()\n",
    "gpt_selection.loc[:, answer_cols] = gpt_selection.loc[:, answer_cols].map(lambda s: s == 'GPT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe indicating when GPT was selected by the majority of annotators for each question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of standardized column names\n",
    "standard_cates = {\n",
    "    'moral': 'Moral',\n",
    "    'moral_neg': 'Negative Moral', \n",
    "    'moral_pos': 'Positive Moral',\n",
    "    'central_topic': 'Central Topic'\n",
    "}\n",
    "\n",
    "# specify the order of the question categories\n",
    "cates_order = ['Moral', 'Positive Moral', 'Negative Moral', 'Central Topic']\n",
    "\n",
    "# the genre of each text\n",
    "genre_type = [x.split(\"_\")[0] for x in df['Input.index'].unique()]\n",
    "\n",
    "# get the number of times GPT is voted as the best among the 3 annotators\n",
    "majority_vote = {}   # uses easy to read tuples as keys\n",
    "orig_col_majority_vote = {}   # same as majority_vote, but using the original column names as keys\n",
    "for col in answer_cols:\n",
    "    # skip the comprehension column\n",
    "    if col != 'comprehension':\n",
    "        cate, type = col.split(\"__\")\n",
    "    else:\n",
    "        cate, type = 'comprehension', 'none'\n",
    "    \n",
    "    # standardize the category name\n",
    "    cate = standard_cates.get(cate, cate)\n",
    "\n",
    "    # get the majority vote counts\n",
    "    majority_vote[(cate, type)] = (gpt_selection[col].values.reshape((-1, 3)).sum(axis=1) > 1)\n",
    "    orig_col_majority_vote[col] = (gpt_selection[col].values.reshape((-1, 3)).sum(axis=1) > 1)\n",
    "\n",
    "df_col_idx = pd.MultiIndex.from_tuples(majority_vote, names=['Category', 'Type'])\n",
    "df_idx = pd.Index(genre_type, name='genre')\n",
    "\n",
    "df_gpt_majority_vote = pd.DataFrame(majority_vote, columns=df_col_idx, index=df_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Fleiss Alpha\n",
    "\n",
    "Get the Fleiss Kappa values for all answer columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fleiss_kappa(annotator_selections_matrix):\n",
    "    return fleiss_kappa(aggregate_raters(annotator_selections_matrix)[0])\n",
    "\n",
    "def get_krippendorff_alpha(annotator_response_matrix):\n",
    "    reliability_data = mturker_responses[col].values.reshape(-1, 3).T\n",
    "    reliability_data = np_numerize_options(reliability_data)\n",
    "    return kd.alpha(reliability_data, level_of_measurement=\"nominal\")\n",
    "\n",
    "def numerize_options(x):\n",
    "    options_to_int = {\n",
    "        'GPT': 0,\n",
    "        'human1': 1,\n",
    "        'human2': 2\n",
    "    }\n",
    "    return options_to_int[x]\n",
    "\n",
    "np_numerize_options = np.vectorize(numerize_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david/anaconda3/envs/thesis/lib/python3.10/site-packages/statsmodels/stats/inter_rater.py:267: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  kappa = (p_mean - p_mean_exp) / (1- p_mean_exp)\n"
     ]
    }
   ],
   "source": [
    "kappa_data = []\n",
    "for col in answer_cols:\n",
    "\n",
    "    # initialize data\n",
    "    kappa_entry = {}\n",
    "    if col == 'comprehension':\n",
    "        cate, type_ = col, 'none'\n",
    "    else:\n",
    "        cate, type_ = col.split(\"__\")\n",
    "\n",
    "    # compute the Fleiss value\n",
    "    annotator_response_matrix = mturker_responses[col].values.reshape(-1, 3) \n",
    "    kappa = get_fleiss_kappa(annotator_response_matrix)\n",
    "    # alpha = get_krippendorff_alpha(annotator_response_matrix) if cate != 'comprehension' else 1\n",
    "\n",
    "    # add data columns\n",
    "    kappa_entry['Fleiss $\\kappa$'] = kappa if not np.isnan(kappa) else 1\n",
    "    # kappa_entry['Krippendorff'] = alpha\n",
    "    kappa_entry['Category'] = cate\n",
    "    kappa_entry['Type'] = type_\n",
    "    \n",
    "    kappa_data.append(kappa_entry)\n",
    "\n",
    "df_fleiss = pd.DataFrame(kappa_data).set_index(['Category']).rename(index=standard_cates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_cols_fleiss = [col for col in df_fleiss.columns if col != 'Type']\n",
    "\n",
    "# separate the coefficients for the best and worst categories\n",
    "best_fleiss = df_fleiss.loc[df_fleiss['Type'] == 'best', rel_cols_fleiss].loc[cates_order]\n",
    "worst_fleiss = df_fleiss.loc[df_fleiss['Type'] == 'worst', rel_cols_fleiss].loc[cates_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Agreement Breakdowns\n",
    "\n",
    "Get the percent agreement breakdowns for all answer columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = ans.shape[0]/3\n",
    "\n",
    "index = []\n",
    "data = []\n",
    "for col in answer_cols:\n",
    "    \n",
    "    # index information\n",
    "    if col != 'comprehension':\n",
    "        cate, type_ = col.split(\"__\")\n",
    "        cate = standard_cates.get(cate, cate)\n",
    "    else:\n",
    "        cate, type_ = 'comprenhension', 'none'\n",
    "    index.append((cate, type_))\n",
    "\n",
    "    # get breakdowns\n",
    "    data_entry = {}\n",
    "    highest_agreement = aggregate_raters(mturker_responses[col].values.reshape(-1, 3))[0].max(axis=1) # number of agreements per story\n",
    "    values, counts = np.unique(highest_agreement, return_counts=True)\n",
    "    for value, count in zip(values, counts):\n",
    "        data_entry[value] = count/n\n",
    "    data.append(data_entry)\n",
    "\n",
    "breakdown_idx_names = pd.MultiIndex.from_tuples(index, names=['Category', 'Type'])\n",
    "\n",
    "breakdowns = pd.DataFrame(data, index=breakdown_idx_names).fillna(0).reset_index().set_index(\"Category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_cols_breakdown = [col for col in breakdowns.columns if col != 'Type']\n",
    "\n",
    "# separate the breakdowns for the best and worst categories\n",
    "best_breakdown = breakdowns.loc[breakdowns['Type'] == 'best', rel_cols_breakdown].loc[cates_order].round(4)*100\n",
    "worst_breakdown = breakdowns.loc[breakdowns['Type'] == 'worst', rel_cols_breakdown].loc[cates_order].round(4)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) GPT Majority Percentage\n",
    "\n",
    "The percentage of the time that GPT was selected by the majority of MTurkers at the most or least applicable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_accs = df_gpt_majority_vote.mean().rename('mean').reset_index().set_index('Category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_best_accs = (gpt_accs[gpt_accs['Type'] == 'best'].loc[cates_order, 'mean'].to_frame().astype(float).round(4)*100)['mean'].rename(\"GPT Accuracy\")\n",
    "gpt_worst_accs = (gpt_accs[gpt_accs['Type'] == 'worst'].loc[cates_order, 'mean'].to_frame().astype(float).round(4)*100)['mean'].rename(\"GPT Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) $\\chi^{2}$ Goodness of Fit\n",
    "\n",
    "Compute p-values for $\\chi^{2}$ goodness of fit test comparing the rate at which GPT was selected by the majority of annotators, relative to random selection. ($P(X \\ge 2)$ for $X \\sim \\text{bin(3, 1/3)}$)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_name = pd.Index(genre_type, name='genre')\n",
    "df_gpt_majority_vote_orig = pd.DataFrame(orig_col_majority_vote, columns=answer_cols, index=idx_name)\n",
    "n = df_gpt_majority_vote_orig.shape[0]\n",
    "\n",
    "chi2_fit_data = {}\n",
    "for col in answer_cols:\n",
    "    \n",
    "    if col == 'comprehension':\n",
    "        continue\n",
    "    cate, type_ = col.split(\"__\")\n",
    "    cate = standard_cates.get(cate, cate)\n",
    "    if cate not in chi2_fit_data:\n",
    "        chi2_fit_data[cate] = dict()\n",
    "\n",
    "    # observed counts\n",
    "    observed_GPT = df_gpt_majority_vote_orig[col].sum()\n",
    "    observed_not_GPT = (~df_gpt_majority_vote_orig[col].astype(bool)).sum()\n",
    "    # expected counts\n",
    "    expected_GPT = n*7/27\n",
    "    expected_not_GPT = n*20/27\n",
    "\n",
    "    # goodness of fit test\n",
    "    f_observed = [observed_GPT, observed_not_GPT]\n",
    "    f_expected = [expected_GPT, expected_not_GPT]\n",
    "    chi2_fit_data[cate][type_] = chisquare(f_obs=f_observed, f_exp=f_expected).pvalue\n",
    "\n",
    "chi2_fit = pd.DataFrame(chi2_fit_data).T.loc[cates_order].round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X^2 values for both most and least applicable\n",
    "chi2_vals_best = chi2_fit['best'].rename(\"$\\chi^{2}$\").round(5)\n",
    "chi2_vals_worst = chi2_fit['worst'].rename(\"$\\chi^{2}$\").round(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Applicable (Table 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>Fleiss $\\kappa$</th>\n",
       "      <th>Krippendorff</th>\n",
       "      <th>GPT Accuracy</th>\n",
       "      <th>$\\chi^{2}$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Moral</th>\n",
       "      <td>13.89</td>\n",
       "      <td>59.03</td>\n",
       "      <td>27.08</td>\n",
       "      <td>0.012169</td>\n",
       "      <td>0.014456</td>\n",
       "      <td>68.06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive Moral</th>\n",
       "      <td>14.58</td>\n",
       "      <td>65.28</td>\n",
       "      <td>20.14</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.002848</td>\n",
       "      <td>60.42</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative Moral</th>\n",
       "      <td>16.67</td>\n",
       "      <td>65.97</td>\n",
       "      <td>17.36</td>\n",
       "      <td>0.031871</td>\n",
       "      <td>0.034112</td>\n",
       "      <td>52.78</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Central Topic</th>\n",
       "      <td>9.72</td>\n",
       "      <td>61.81</td>\n",
       "      <td>28.47</td>\n",
       "      <td>0.085116</td>\n",
       "      <td>0.087234</td>\n",
       "      <td>67.36</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    1      2      3  Fleiss $\\kappa$  Krippendorff  \\\n",
       "Moral           13.89  59.03  27.08         0.012169      0.014456   \n",
       "Positive Moral  14.58  65.28  20.14         0.000535      0.002848   \n",
       "Negative Moral  16.67  65.97  17.36         0.031871      0.034112   \n",
       "Central Topic    9.72  61.81  28.47         0.085116      0.087234   \n",
       "\n",
       "                GPT Accuracy  $\\chi^{2}$  \n",
       "Moral                  68.06         0.0  \n",
       "Positive Moral         60.42         0.0  \n",
       "Negative Moral         52.78         0.0  \n",
       "Central Topic          67.36         0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least Applicable (Table 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>Fleiss $\\kappa$</th>\n",
       "      <th>Krippendorff</th>\n",
       "      <th>GPT Accuracy</th>\n",
       "      <th>$\\chi^{2}$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Moral</th>\n",
       "      <td>16.67</td>\n",
       "      <td>58.33</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.123362</td>\n",
       "      <td>0.125391</td>\n",
       "      <td>11.11</td>\n",
       "      <td>0.00005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive Moral</th>\n",
       "      <td>20.83</td>\n",
       "      <td>63.19</td>\n",
       "      <td>15.97</td>\n",
       "      <td>0.037815</td>\n",
       "      <td>0.040042</td>\n",
       "      <td>11.81</td>\n",
       "      <td>0.00011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative Moral</th>\n",
       "      <td>23.61</td>\n",
       "      <td>63.19</td>\n",
       "      <td>13.19</td>\n",
       "      <td>-0.004914</td>\n",
       "      <td>-0.002588</td>\n",
       "      <td>15.97</td>\n",
       "      <td>0.00642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Central Topic</th>\n",
       "      <td>13.19</td>\n",
       "      <td>61.81</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.134040</td>\n",
       "      <td>0.136044</td>\n",
       "      <td>7.64</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    1      2      3  Fleiss $\\kappa$  Krippendorff  \\\n",
       "Moral           16.67  58.33  25.00         0.123362      0.125391   \n",
       "Positive Moral  20.83  63.19  15.97         0.037815      0.040042   \n",
       "Negative Moral  23.61  63.19  13.19        -0.004914     -0.002588   \n",
       "Central Topic   13.19  61.81  25.00         0.134040      0.136044   \n",
       "\n",
       "                GPT Accuracy  $\\chi^{2}$  \n",
       "Moral                  11.11     0.00005  \n",
       "Positive Moral         11.81     0.00011  \n",
       "Negative Moral         15.97     0.00642  \n",
       "Central Topic           7.64     0.00000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Most Applicable (Table 4)\")\n",
    "display(pd.concat([best_breakdown, best_fleiss, gpt_best_accs, chi2_vals_best], axis=1))\n",
    "\n",
    "print(\"Least Applicable (Table 4)\")\n",
    "display(pd.concat([worst_breakdown, worst_fleiss, gpt_worst_accs, chi2_vals_worst], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 10\n",
    "\n",
    "Percent of passages by genre where the GPT response was selected by a majority of AMT workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy of GPT selection by genre\n",
    "gpt_genre_accs = df_gpt_majority_vote.groupby('genre').mean().T.loc[cates_order].reset_index().set_index('Category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_cols = [col for col in gpt_genre_accs.columns if col != 'Type']\n",
    "\n",
    "best_accs_by_genre = gpt_genre_accs.loc[gpt_genre_accs['Type'] == 'best', genre_cols]\n",
    "best_accs_by_genre = best_accs_by_genre.loc[cates_order].round(4)*100\n",
    "\n",
    "worst_accs_by_genre = gpt_genre_accs.loc[gpt_genre_accs['Type'] == 'worst', genre_cols]\n",
    "worst_accs_by_genre = worst_accs_by_genre.loc[cates_order].round(4)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Applicable by Genre (Table 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>genre</th>\n",
       "      <th>Book</th>\n",
       "      <th>Folktale</th>\n",
       "      <th>Movies-TV</th>\n",
       "      <th>News</th>\n",
       "      <th>Reddit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Moral</th>\n",
       "      <td>62.50</td>\n",
       "      <td>78.12</td>\n",
       "      <td>56.25</td>\n",
       "      <td>73.44</td>\n",
       "      <td>43.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive Moral</th>\n",
       "      <td>56.25</td>\n",
       "      <td>62.50</td>\n",
       "      <td>62.50</td>\n",
       "      <td>57.81</td>\n",
       "      <td>68.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative Moral</th>\n",
       "      <td>56.25</td>\n",
       "      <td>50.00</td>\n",
       "      <td>62.50</td>\n",
       "      <td>51.56</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Central Topic</th>\n",
       "      <td>75.00</td>\n",
       "      <td>65.62</td>\n",
       "      <td>37.50</td>\n",
       "      <td>73.44</td>\n",
       "      <td>68.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "genre            Book  Folktale  Movies-TV   News  Reddit\n",
       "Category                                                 \n",
       "Moral           62.50     78.12      56.25  73.44   43.75\n",
       "Positive Moral  56.25     62.50      62.50  57.81   68.75\n",
       "Negative Moral  56.25     50.00      62.50  51.56   50.00\n",
       "Central Topic   75.00     65.62      37.50  73.44   68.75"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least Applicable by Genre (Table 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>genre</th>\n",
       "      <th>Book</th>\n",
       "      <th>Folktale</th>\n",
       "      <th>Movies-TV</th>\n",
       "      <th>News</th>\n",
       "      <th>Reddit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Moral</th>\n",
       "      <td>12.50</td>\n",
       "      <td>6.25</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.81</td>\n",
       "      <td>18.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive Moral</th>\n",
       "      <td>6.25</td>\n",
       "      <td>12.50</td>\n",
       "      <td>12.5</td>\n",
       "      <td>12.50</td>\n",
       "      <td>12.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative Moral</th>\n",
       "      <td>18.75</td>\n",
       "      <td>12.50</td>\n",
       "      <td>12.5</td>\n",
       "      <td>17.19</td>\n",
       "      <td>18.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Central Topic</th>\n",
       "      <td>6.25</td>\n",
       "      <td>3.12</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.81</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "genre            Book  Folktale  Movies-TV   News  Reddit\n",
       "Category                                                 \n",
       "Moral           12.50      6.25       25.0   7.81   18.75\n",
       "Positive Moral   6.25     12.50       12.5  12.50   12.50\n",
       "Negative Moral  18.75     12.50       12.5  17.19   18.75\n",
       "Central Topic    6.25      3.12       25.0   7.81    0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Most Applicable by Genre (Table 10)\")\n",
    "display(best_accs_by_genre)\n",
    "print(\"Least Applicable by Genre (Table 10)\")\n",
    "display(worst_accs_by_genre)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
